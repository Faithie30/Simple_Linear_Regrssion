{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation and Simple Linear Regression\n",
    "\n",
    "This is the process that gives us the internal and the cross-validation measures of <b> predictive accuracy </b>for a <b>simple linear regression</b>. The data are <b>randomly assigned</b> to a number of \"folds\", which in our context is the <b>test</b> and <b>training</b> folds. Each fold is removed, in turn, while the <b>remaining data</b> is used to <b>re-fit</b> the regression model and to <b>predict</b> at the <b>deleted observations.</b>\n",
    "\n",
    "- We will predict employee salaries from different employee characteristics (or features). <br> \n",
    "- We are going to use a simple supervised learning technique: linear regression. \n",
    "- We want to build a simple model to determine how well Years Worked predicts an employee’s salary. Years Worked predicts an employee’s salary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data into a dataframe\n",
    "\n",
    "salary = pd.read_csv('data/salary.csv')\n",
    "salary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Type of data</center></h1> \n",
    "\n",
    "| Continuous | Categorical | Binary |\n",
    "| --- | --- | --- |\n",
    "| Salary | position | degree |\n",
    "| exprior | field | otherqual |\n",
    "| Yearsworked | - | male |\n",
    "| market | - | - |\n",
    "| yearsranked | - | -|\n",
    "| yearsabs | - | - |\n",
    "\n",
    "<h1><center>Feature description</center></h1> \n",
    "\n",
    "| Feature | Description |\n",
    "| --- | --- |\n",
    "| exprior | Years of experience prior to working in this field |\n",
    "| Yearsworked | Years worked in this field |\n",
    "| yearsrank | Years worked at current rank |\n",
    "| market | Market value (1 = salary at market value for position, <br> <1 salary lower than market value for position,<br> >1 salary higher than market value for position) |\n",
    "| degree | Has degree (0 = no 1= yes) |\n",
    "| otherqual | Has other post-secondary qualification (0 = no, 1=yes) |\n",
    "| position | Position (1 = Junior Employee 2=Manager 3= Executive) |\n",
    "| male | 0 = no 1 1=yes |\n",
    "| Field | Field of work (1 = Engineering 2=Finance 3=Human Resource 4=Marketing) |\n",
    "| yearsabs |Years absent from work (e.g. due to illness / child rearing / personal reasons)|\n",
    "\n",
    "<h1><center>Response description</center></h1> \n",
    "\n",
    "| Response | Description |\n",
    "| --- | --- |\n",
    "| <font color='black'> salary </font>| <font color='black'>  Annual salary in dollars </font> | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cleaning data\n",
    "Data cleaning is the process of detecting and correcting corrupt or inaccurate data from a dataset, table, or database and refers to identifying incomplete, incorrect, inaccurate or irrelevant parts of the data and then replacing, modifying, or deleting the dirty or coarse data.\n",
    "### 2.1 Examining missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for missing values for our dataset\n",
    "\n",
    "salary.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling the missing values with the average\n",
    "salary = salary.fillna(salary['salary'].mean())\n",
    "salary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What we did with the missing values in the data\n",
    "\n",
    "- We <b>filled</b> the missing value that appeared in the <b>salary</b> column with the <b>mean</b> of that column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Examing duplicates within the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping duplicates within the dataset\n",
    "salary.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dealing with duplicates within the dataset\n",
    "\n",
    "We dropped any duplicates that may exist within the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Examining outliers within the dataset\n",
    "In statistics, an outlier is an observation point that is distant from other observations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Checking for extreme values\n",
    "sns.set()\n",
    "sns.set(style=\"whitegrid\")\n",
    "fig, axes = plt.subplots(1,2, figsize=(15, 15))\n",
    "sns.boxplot(x=salary[\"salary\"], ax=axes[0], data = salary)\n",
    "sns.boxplot(x=salary[\"yearsworked\"], ax=axes[1],data = salary);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the outliers\n",
    "removed_outliers = salary['salary'].between(salary['salary'].quantile(.05), salary['salary'].quantile(.95))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Outliers\n",
    "\n",
    "Using the box plot method have observed <b> two outliers</b> for the salary values, and <b>none</b> for the yearsworked values. \n",
    "How we intend on dealing with the outliers is to <b>remove </b> them, so that the model that we will build will not be affected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Spliting data\n",
    "These are two rather important concepts in data science and data analysis and are used as tools to prevent (or at least minimize) overfitting. We usually fit the model on a training set in order to make predications on a data that wasn’t trained (general data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split our data\n",
    "x = salary[['exprior','yearsworked','yearsrank','market','degree','otherqual','position', 'male','Field','yearsabs']]\n",
    "y = salary['salary']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.20)\n",
    "y_train = pd.DataFrame(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Viewing the split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#showcasing the first 5 observations of the feature variables\n",
    "X_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#showcasing the first 5 observations of the response variable (salary)\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Describing the dataset of the response variable (salary)\n",
    "y_train.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Describing the dataset of the feature variables\n",
    "X_train.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describing the datasets\n",
    " - The training dataset contains <b> 80% of the overall dataset </b> and has been divided into two datasets the <b>feautures dataset </b> and the <b>response variable dataset</b>\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Distribution of the data\n",
    "The distribution of a statistical data set (or a population) is a listing or function showing all the possible values (or intervals) of the data and how often they occur.\n",
    "\n",
    "### 4.1 Histograms of salaries and years worked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating histograms with density line\n",
    "\n",
    "sns.set()\n",
    "sns.set(style=\"whitegrid\")\n",
    "fig, axes = plt.subplots(1, 2,figsize=(20, 6))\n",
    "sns.distplot(X_train[\"yearsworked\"], hist=True, kde=True, \n",
    "             bins=int(180/5), color = 'darkblue', \n",
    "             hist_kws={'edgecolor':'black'},\n",
    "             kde_kws={'linewidth': 4}, ax=axes[0])\n",
    "\n",
    "sns.distplot(y_train, hist=True, kde=True, \n",
    "             bins=int(180/5), color = 'darkblue', \n",
    "             hist_kws={'edgecolor':'black'},\n",
    "             kde_kws={'linewidth': 4}, ax=axes[1])\n",
    "\n",
    "axes[0].set_title('The histogram for years worked')\n",
    "axes[1].set_title('The histogram for salary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Scatterplot of salary and years worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating scatterplot\n",
    "combined = pd.concat([X_train, y_train], axis=1)\n",
    "combined.head()\n",
    "sns.regplot(x=combined['yearsworked'], y=combined['salary']);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Distribution of the salary and number of years worked\n",
    "- Both graphs show a distribution that is not normal, they are both skewed to the right\n",
    "- The salary distribution graph shows that there are more people earning between 35 000 dollars and 60 000 dollars and fewer people earning more than 75 000 dollars\n",
    "- The number of years worked distribution graph shows that more people have worked within the years 0 to 26 years whereas the least have worked greater than 30 years\n",
    "\n",
    "##### Scatter plot of the salary vs number of years worked\n",
    "\n",
    "The <b> line of best fit </b> shows a <b>strong positive relationship</b> between years worked and the salary earned. which implies that when the number of years worked <b> increases </b> the salary inturn also <b> increase </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modeling\n",
    "### 5.1 Simple linear regression model using statsmodels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit regression model \n",
    "results = smf.ols('salary ~ yearsworked', data=combined).fit()\n",
    "\n",
    "# Inspect the results\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Analysis of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2.1 Does the model significantly predict the dependent variable? \n",
    "\n",
    "<b> According to the R-squared criterion:</b>\n",
    "- Because there is only one feature variable modelled, we can either use the R-squared or the adjusted R-squared as the adjusted R-sqaured helps us with penalizing the R-squared for every variable inputed into the model.\n",
    "- R-sqaured = 0.377 and adjusted R-squared = 0.376\n",
    "  - So we can sonclude that the salary response variable is explained by 37% of the feauture variable which is number of years worked.\n",
    "  \n",
    "\n",
    "<b>According to the pvalue criterion: </b> <br>\n",
    "H0: Does not have signficant relationship <br>\n",
    "Ha: Has significant relationship\n",
    "-  The pvalue given in the OLS is 0, and this is less than the significance level of 5%. Therefore we reject the null hypothesis stating that there is no evident relationship between the predictor and the response variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  5.2.2 What percentage of the variance in employees’ salaries is accounted for by the number of years they have worked\n",
    "- The graph shows that about 37% of the data fits the regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2.3 Interpretation of coeficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Intercept: </b> \n",
    "- The coefficient for number of years worked is 40570\n",
    "  - That is, if the number of years worked is 0, the base salary will be $40570 \n",
    "\n",
    "<b> Number of years worked: </b> \n",
    "- The coefficient for number of years worked is 819.77\n",
    "  - That is, if the number of years worked increased by one unit, the salary will then increase by $819.77\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2.4 Confidence intervals\n",
    "\n",
    "- A 95% confidence interval is a range of values that you can be 95% certain that it contains the true mean of the population. Idealy, with regards to the interval,the true population mean value should be on that interval. If a confidence interval does not include a particular value, we can say that it is not likely that the particular value is the true population mean. However, even if a particular value is within the interval, we shouldn't conclude that the population mean equals that specific value.\n",
    "\n",
    "- The confidence interval can also be used for coefficients of the regression model Use the confidence interval to assess the estimate of the population coefficient for each term in the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2.4 What do the 95% confidence intervals [0.025, 0.975] mean?\n",
    "\n",
    "You can be 95% confident that the confidence interval contains the value of the coefficient for the population.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate expected salary for someone who worked for 12 years\n",
    "\n",
    "year_12 = pd.DataFrame({'yearsworked':[12]})\n",
    "prints = results.predict(year_12)\n",
    "p=prints.iloc[0]\n",
    "p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if combined.yearsworked == 12: return combined[combined.salary[i]] for i in combined\n",
    "\n",
    "year_12 = pd.DataFrame(combined[combined.yearsworked == 12]['salary'])\n",
    "year_12.sort_values(by=['salary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate expected salary for someone who worked for 80 years\n",
    "year_12 = pd.DataFrame({'yearsworked':[80]})\n",
    "prints = results.predict(year_12)\n",
    "p=prints.iloc[0]\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if combined.yearsworked == 80: return combined[combined.salary[i]] for i in combined\n",
    "\n",
    "year_80 = pd.DataFrame(combined[combined.yearsworked == 80]['salary'])\n",
    "year_80.sort_values(by=['salary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Are there any problems with this prediction? If so, what are they?\n",
    "\n",
    "- There was no problem in predicting the salary for the 12 years worked as 12 years is within the range of our dataset (Interpolation).\n",
    "- The problem comes into play when we are predicting for the 80 years worked as this is not within the range (extrapolation)\n",
    "- The disadvantage of predicting on extrapolated data is that it is unreliable if there are significant fluctuations in historical data. Assumes past trend will continue into the future – unlikely in many competitive business environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Correlation\n",
    "Correlation is a statistical technique that can show whether and how strongly pairs of variables are related."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Correlation Matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = np.random.RandomState(0)\n",
    "df = pd.DataFrame(rs.rand(10, 10))\n",
    "corr = combined.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Correlation heat map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = combined.corr()\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    correlation, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_corr = combined[['salary', 'market', 'yearsworked', 'yearsrank']]\n",
    "\n",
    "sns.pairplot(salary_corr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting correlation graph\n",
    "\n",
    "- The above table shows the correlation between two variables, showcasing its <b>strengths and direction</b>. This helps us to select the features that have a significant impact on the response variable and therefore helping us predict the salaries.\n",
    "\n",
    "- looking at the correlation between the response variable Salary and the feature variable yearsworked which is <b>0.623589</b>. This is a <b> fairly strong positive relationship </b>, and therefore we can assume as the number of years worked increases the value of salary also increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have only looked at the number of years an employee has worked. What other employee characteristics might influence their salary?\n",
    "\n",
    "Looking at the the correlation matrix, the features that have good correlation with salary are yearsrank, position and field. The rest of the features have less than 50% correlation with salary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. RSME\n",
    "Root mean squared error (RMSE): RMSE is a quadratic scoring rule that also measures the average magnitude of the error. It’s the square root of the average squared differences between prediction and actual observation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RSME for training dataset\n",
    "train = results.predict(X_train['yearsworked'])\n",
    "\n",
    "m_s_e = sqrt(mse(y_train, train))\n",
    "m_s_e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RSME for test dataset\n",
    "test = results.predict(X_test['yearsworked'])\n",
    "\n",
    "msse = sqrt(mse(y_test, test))\n",
    "msse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What is the difference in the Root Mean Square Error (RMSE) between the training and test sets? Is there any evidence of overfitting?\n",
    "\n",
    "Our model performs better on the train dataset than it does on the test set. With this we can now conclude that the model is overfitted. We say this because our model shows low bias but high variance. To better train our model we need to identify relevant variables and terms that you are likely to influence our outcome that we hoping for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE_train is bigger than  RMSE_test by slight margin therefore there is overfitting on our model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
